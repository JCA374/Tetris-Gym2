# Complete Action Mapping Fix + Exploration Issue

## ðŸ”´ TWO CRITICAL BUGS FOUND AND FIXED

### Bug #1: Wrong Action Mapping in `config.py` âœ… FIXED
### Bug #2: Wrong Action Mapping in `agent.py` âœ… FIXED

---

## The Problems

### Problem 1: config.py had wrong action IDs

**Before (WRONG):**
```python
ACTION_NOOP=0; ACTION_LEFT=1; ACTION_RIGHT=2; ACTION_DOWN=3
ACTION_ROTATE_CW=4; ACTION_ROTATE_CCW=5; ACTION_HARD_DROP=6; ACTION_SWAP=7
```

**After (FIXED):**
```python
ACTION_LEFT=0; ACTION_RIGHT=1; ACTION_DOWN=2; ACTION_ROTATE_CW=3
ACTION_ROTATE_CCW=4; ACTION_HARD_DROP=5; ACTION_SWAP=6; ACTION_NOOP=7
```

### Problem 2: agent.py ALSO had wrong action IDs

**Before (WRONG) - agent.py lines 208-233:**
```python
if r < 0.175:
    return 1  # LEFT   <-- WRONG! Should be 0
elif r < 0.350:
    return 2  # RIGHT  <-- WRONG! Should be 1
elif r < 0.450:
    return 4  # ROTATE_CW  <-- WRONG! Should be 3
```

**After (FIXED):**
```python
if r < 0.25:
    return 0  # LEFT (action 0) âœ…
elif r < 0.40:
    return 1  # RIGHT (action 1) âœ…
elif r < 0.50:
    return 2  # DOWN (action 2) âœ…
elif r < 0.60:
    return 3  # ROTATE_CW (action 3) âœ…
```

---

## Why You Saw Center-Stacking

Your agent showed: `Column heights: [0, 0, 0, 0, 20, 20, 18, 17, 15, 14]`

**Root causes:**

1. **Wrong action mapping** â†’ When agent tried LEFT (old action 1), it actually moved RIGHT
2. **Insufficient LEFT exploration** â†’ Even with correct actions, random policy only uses column 0 in 4% of episodes
3. **Agent never learned LEFT** â†’ Stuck in local optimum playing only center columns

---

## Test Results Proving the Fix

### âœ… Environment Works Correctly

**Coordinate mapping test:**
- self.x=4 (raw) â†’ column 0 (playable) âœ…
- self.x=5 (raw) â†’ column 1 (playable) âœ…
- self.x=6 (raw) â†’ column 2 (playable) âœ…
- ALL columns 0-9 are accessible!

### âœ… Exploration Distribution Matters

**Random policy (12.5% per action):**
- Column 0 usage: 4% of episodes
- Column 1 usage: 20% of episodes
- Columns 4-6 usage: 100% of episodes

**LEFT-biased policy (50% LEFT actions):**
- Column 0 usage: 78% of episodes âœ…
- Column 1 usage: 96% of episodes âœ…
- ALL columns used heavily!

**Conclusion:** Agent needs **more LEFT actions during exploration** to discover leftmost columns.

---

## What Changed in the Fix

### config.py (line 48-53)
âœ… Aligned action constants with tetris-gymnasium v0.3.0 ActionsMapping

### agent.py (lines 208-238)
âœ… Fixed exploration action IDs
âœ… Increased LEFT probability: 17.5% â†’ **25%**
âœ… Decreased RIGHT probability: 17.5% â†’ **15%**

This bias encourages the agent to explore leftmost columns which are hard to reach.

---

## Training Impact

### Before Fixes:
```
Exploration during episode:
  Agent selects "LEFT" (old action 1)
  â†’ Environment receives 1
  â†’ Piece moves RIGHT (actual action 1)
  â†’ Agent learns "LEFT makes pieces go right" (nonsense!)
  â†’ Agent avoids LEFT
  â†’ Center-stacking emerges
```

### After Fixes:
```
Exploration during episode:
  Agent selects "LEFT" (action 0)
  â†’ Environment receives 0
  â†’ Piece moves LEFT âœ…
  â†’ Agent learns "LEFT moves left"
  â†’ 25% exploration probability for LEFT
  â†’ Agent discovers columns 0-3 are usable
  â†’ Better space utilization
```

---

## Action Plan

### Step 1: Delete ALL old training data âš ï¸ CRITICAL

```bash
rm -rf models/*
rm -rf logs/*
```

**Why:** All previous training used wrong action mappings. The Q-network learned:
- "Action 1 moves right" (thought it was LEFT)
- "Action 2 moves down" (thought it was RIGHT)
- etc.

This knowledge is completely inverted and WILL hurt new training if reused.

### Step 2: Verify fixes are applied

Check both files have correct mappings:

```bash
# Check config.py
grep "ACTION_LEFT" config.py
# Should show: ACTION_LEFT=0

# Check agent.py
grep -A 2 "return 0.*LEFT" src/agent.py
# Should show: return 0  # LEFT (action 0)
```

### Step 3: Start fresh training

```bash
.venv/bin/python train.py \
    --episodes 5000 \
    --reward_shaping positive \
    --force_fresh \
    --epsilon_start 1.0 \
    --epsilon_decay 0.9999
```

**Important parameters:**
- `--force_fresh`: Ensures no old models are loaded
- `--epsilon_start 1.0`: Start with 100% exploration
- `--epsilon_decay 0.9999`: Slow decay so agent explores longer

### Step 4: Monitor column usage

Watch the training logs for:

```
Column heights: [X, X, X, X, ...]
```

**Good signs:**
- âœ… Columns 0-3 show non-zero heights
- âœ… Heights distributed across all 10 columns
- âœ… Not just columns 4-6

**Bad signs (means fix didn't apply):**
- âŒ Still seeing [0, 0, 0, 0, 20, 20, ...]
- âŒ Only columns 4-6 used

If you still see bad signs after 500 episodes, stop and verify the fixes are actually in the code.

---

## Expected Training Results

### Episodes 0-500: Discovery Phase
```
Column heights: [0, 1, 5, 12, 18, 19, 17, 10, 3, 0]
                 â†‘  â†‘  â†‘                      â†‘  â†‘
                 Starting to explore left    Right side too
Lines/episode: 0-2
Epsilon: 1.0 â†’ 0.95
```

### Episodes 500-1500: Learning Phase
```
Column heights: [2, 8, 12, 15, 18, 19, 18, 14, 8, 3]
                 â†‘  â†‘  â†‘                         â†‘  â†‘
                 All columns used!
Lines/episode: 2-10
Epsilon: 0.95 â†’ 0.60
```

### Episodes 1500-5000: Mastery Phase
```
Column heights: [8, 10, 12, 14, 15, 14, 13, 11, 9, 7]
                 â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘
                 Balanced distribution!
Lines/episode: 10-50+
Epsilon: 0.60 â†’ 0.20
```

---

## Why This Took So Long to Find

1. **Action mapping seems trivial** â†’ Easy to overlook
2. **Bug was in TWO places** â†’ Fixed config.py but not agent.py initially
3. **Center-stacking looked like environment bug** â†’ Actually was control inversion
4. **Symptom (center-stacking) != Cause (wrong actions)** â†’ Red herring

The user's intuition was RIGHT - center-stacking was abnormal. But the root cause was inverted controls, not board size or collision detection.

---

## Verification Checklist

Before starting training, verify:

- [ ] `config.py` line 51 shows: `ACTION_LEFT=0`
- [ ] `config.py` line 52 shows: `ACTION_HARD_DROP=5`
- [ ] `agent.py` line 226 shows: `return 0  # LEFT (action 0)`
- [ ] `agent.py` line 236 shows: `return 5  # HARD_DROP (action 5)`
- [ ] Deleted `models/*` directory
- [ ] Deleted `logs/*` directory

If ALL boxes checked âœ… â†’ Ready to train!

---

## Summary

| Issue | Root Cause | Fix | File |
|-------|-----------|-----|------|
| Center-stacking | Wrong action IDs | Aligned with tetris-gymnasium | `config.py` |
| Agent exploration | Wrong action IDs | Fixed IDs + increased LEFT to 25% | `agent.py` |
| Columns 0-3 unused | Insufficient LEFT exploration | Agent will explore left more | `agent.py` |

**Status:** âœ… READY TO TRAIN

The agent will now:
1. Use correct action mappings
2. Explore LEFT more (25% vs 17.5%)
3. Discover columns 0-3 are usable
4. Learn balanced column distribution
5. Clear more lines (once it masters placement)

Good luck with training! ðŸš€
