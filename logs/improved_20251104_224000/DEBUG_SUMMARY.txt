================================================================================
TETRIS AI TRAINING - DEBUG SUMMARY
================================================================================
Generated: 2025-11-05 05:34:41
Experiment: improved_20251104_224000

================================================================================
TRAINING CONFIGURATION
================================================================================
Total episodes:        10000
Episodes trained:      10000 (from 0 to 10000)
Training time:         414.7 minutes (6.91 hours)
Time per episode:      2.49 seconds
Learning rate:         0.0005
Batch size:            64
Gamma (discount):      0.99
Epsilon start:         1.0
Epsilon end:           0.01
Epsilon decay:         0.9995
Final epsilon:         0.0200
Model type:            dqn
Complete vision:       True
CNN enabled:           True

================================================================================
CURRICULUM PROGRESSION
================================================================================
Final stage:           clean_spreading

Stage Thresholds:
  Stage 1 (Foundation):        Episodes 0-500
  Stage 2 (Clean Placement):   Episodes 500-1000
  Stage 3 (Spreading Found):   Episodes 1000-2000
  Stage 4 (Clean Spreading):   Episodes 2000-5000
  Stage 5 (Line Clearing):     Episodes 5000+

Stage Transitions:
  Episode   500: foundation           â†’ clean_placement
  Episode  1000: clean_placement      â†’ spreading_foundation
  Episode  2000: spreading_foundation â†’ clean_spreading

================================================================================
PERFORMANCE METRICS (Last 100 Episodes)
================================================================================
Average reward:          9856.9
Average steps:            311.7
Average lines/ep:          0.21
Total lines cleared:        868
Overall lines/ep:         0.087
First line at:         Episode 741

Board Quality Metrics:
  Holes:                   48.2  (target: <15)
  Columns used:            10.0/10  (target: â‰¥8)
  Completable rows:         0.6  (target: 3-5)
  Clean rows:               2.9  (target: 10-15)

================================================================================
SUCCESS CRITERIA EVALUATION
================================================================================
Stage 2 (Clean Placement):  âŒ FAILED
  Holes: 48.2 (target: <15)

Stage 4 (Clean Spreading):  âœ… SUCCESS
  Columns used: 10.0/10 (target: â‰¥8)

Stage 5 (Line Clearing):    âŒ FAILED
  Lines/episode: 0.21 (target: â‰¥2.0)

Overall Performance:        ðŸ‘ GOOD PROGRESS

================================================================================
PROBLEM ANALYSIS & RECOMMENDATIONS
================================================================================
Problems Detected:
  âš ï¸  WARNING: Holes high (30-50) - Board quality poor
  âœ… Spreading achieved (â‰¥8 columns)!
  âš ï¸  WARNING: Low line clears (<1/episode) in Stage 5
  âš ï¸  WARNING: Building tall towers with many holes

Recommendations:
  â†’ Agent needs more time in earlier stages
  â†’ Consider increasing hole penalty by 20-30%
  â†’ Agent needs to reduce holes first
  â†’ Increase completable_rows bonus
  â†’ Continue training for 2000-3000 more episodes
  â†’ Agent getting survival bonus despite bad board
  â†’ Make survival bonus more conditional (only if holes <20)
  â†’ Add explicit height penalty for towers >15

================================================================================
NEXT STEPS
================================================================================
ðŸ‘ Good progress! Agent has learned spreading.

Suggested next steps:
  1. Continue training for 3000 more episodes
  2. Focus on reducing holes to enable line clears
  3. Monitor completable_rows metric - should increase
  4. Expect first consistent line clears around episode 6000-8000

================================================================================
REWARD FUNCTION EFFECTIVENESS
================================================================================
Current stage: clean_spreading

Typical reward for current performance (stage: clean_spreading):
  Assumptions: 48 holes, 10 columns, 311 steps

  Hole penalty:        -2.5 Ã— 48 = -120.5
  Completable rows:    +10.0 Ã— 0.6 = 6.2
  Clean rows:          +7.0 Ã— 2.9 = 20.3
  Spread bonus:        ~+25.0
  Columns bonus:       +5.0 Ã— 10 = 50.0

If rewards are consistently negative:
  â†’ Agent is being penalized more than rewarded
  â†’ This is OK in early stages (learning from mistakes)
  â†’ Should become positive by episode 3000-5000

If rewards are too high (>10000) without line clears:
  â†’ Agent may be exploiting survival bonus
  â†’ Check if holes are high - survival should be conditional
  â†’ Hole penalty may need to be stronger

================================================================================
OUTPUT FILES
================================================================================
Log directory:         logs/improved_20251104_224000
Board states:          board_states.txt
Episode log (CSV):     episode_log.csv
Reward plot:           reward_progress.png
Metrics plot:          training_metrics.png
Debug summary:         DEBUG_SUMMARY.txt (this file)

================================================================================
USEFUL DEBUG COMMANDS
================================================================================
View recent board states:
  tail -100 logs/improved_20251104_224000/board_states.txt

Analyze hole progression:
  awk -F',' 'NR>1 {print $4,$6}' logs/improved_20251104_224000/episode_log.csv | tail -100

Check line clearing progress:
  awk -F',' 'NR>1 {sum+=$7} NR%1000==0 {print NR,sum}' logs/improved_20251104_224000/episode_log.csv

Resume training:
  python train_progressive_improved.py --episodes 15000 --resume

================================================================================
END OF DEBUG SUMMARY
================================================================================