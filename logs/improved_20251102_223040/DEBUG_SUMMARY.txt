‚ö†Ô∏è  TRAINING INTERRUPTED AT EPISODE 14112

================================================================================
TETRIS AI TRAINING - DEBUG SUMMARY
================================================================================
Generated: 2025-11-02 22:38:35
Experiment: improved_20251102_223040

================================================================================
TRAINING CONFIGURATION
================================================================================
Total episodes:        14112
Episodes trained:      600 (from 13512 to 14112)
Training time:         7.9 minutes (0.13 hours)
Time per episode:      0.79 seconds
Learning rate:         0.0005
Batch size:            64
Gamma (discount):      0.99
Epsilon start:         1.0
Epsilon end:           0.01
Epsilon decay:         0.9995
Final epsilon:         0.3414
Model type:            dqn
Complete vision:       True
CNN enabled:           True

================================================================================
CURRICULUM PROGRESSION
================================================================================
Final stage:           line_clearing_focus

Stage Thresholds:
  Stage 1 (Foundation):        Episodes 0-500
  Stage 2 (Clean Placement):   Episodes 500-1000
  Stage 3 (Spreading Found):   Episodes 1000-2000
  Stage 4 (Clean Spreading):   Episodes 2000-5000
  Stage 5 (Line Clearing):     Episodes 5000+

Stage Transitions:
  Episode 13512: foundation           ‚Üí line_clearing_focus

================================================================================
PERFORMANCE METRICS (Last 100 Episodes)
================================================================================
Average reward:         -9144.9
Average steps:            102.2
Average lines/ep:          0.01
Total lines cleared:         12
Overall lines/ep:         0.020
First line at:         Episode 13537

Board Quality Metrics:
  Holes:                   43.4  (target: <15)
  Columns used:             9.8/10  (target: ‚â•8)
  Completable rows:         0.1  (target: 3-5)
  Clean rows:               4.6  (target: 10-15)

================================================================================
SUCCESS CRITERIA EVALUATION
================================================================================
Stage 2 (Clean Placement):  ‚ùå FAILED
  Holes: 43.4 (target: <15)

Stage 4 (Clean Spreading):  ‚úÖ SUCCESS
  Columns used: 9.8/10 (target: ‚â•8)

Stage 5 (Line Clearing):    ‚ùå FAILED
  Lines/episode: 0.01 (target: ‚â•2.0)

Overall Performance:        üëç GOOD PROGRESS

================================================================================
PROBLEM ANALYSIS & RECOMMENDATIONS
================================================================================
Problems Detected:
  ‚ö†Ô∏è  WARNING: Holes high (30-50) - Board quality poor
  ‚úÖ Spreading achieved (‚â•8 columns)!
  ‚ùå CRITICAL: No line clears despite 5000+ episodes
  ‚ö†Ô∏è  WARNING: No completable rows (rows with 8-9 filled, no holes)
  ‚ö†Ô∏è  WARNING: Building tall towers with many holes

Recommendations:
  ‚Üí Agent needs more time in earlier stages
  ‚Üí Consider increasing hole penalty by 20-30%
  ‚Üí Agent likely has too many holes to clear lines
  ‚Üí Check completable_rows metric (should be >0)
  ‚Üí May need to restart with stronger hole penalties
  ‚Üí Agent not learning to set up line clears
  ‚Üí Increase completable_rows bonus significantly
  ‚Üí This is the key metric bridging placement ‚Üí line clears
  ‚Üí Agent getting survival bonus despite bad board
  ‚Üí Make survival bonus more conditional (only if holes <20)
  ‚Üí Add explicit height penalty for towers >15

================================================================================
NEXT STEPS
================================================================================
üëç Good progress! Agent has learned spreading.

Suggested next steps:
  1. Continue training for 3000 more episodes
  2. Focus on reducing holes to enable line clears
  3. Monitor completable_rows metric - should increase
  4. Expect first consistent line clears around episode 6000-8000

================================================================================
REWARD FUNCTION EFFECTIVENESS
================================================================================
Current stage: line_clearing_focus

Typical reward for current performance (stage: line_clearing_focus):
  Assumptions: 43 holes, 9 columns, 102 steps

  Hole penalty:        -3.5 √ó 43 = -152.0
  Completable rows:    +15.0 √ó 0.1 = 2.2
  Clean rows:          +12.0 √ó 4.6 = 54.7
  Spread bonus:        ~+20.0
  Columns bonus:       +4.0 √ó 10 = 39.1
  Survival bonus:      +0.0 (NO bonus, holes ‚â•30)

If rewards are consistently negative:
  ‚Üí Agent is being penalized more than rewarded
  ‚Üí This is OK in early stages (learning from mistakes)
  ‚Üí Should become positive by episode 3000-5000

If rewards are too high (>10000) without line clears:
  ‚Üí Agent may be exploiting survival bonus
  ‚Üí Check if holes are high - survival should be conditional
  ‚Üí Hole penalty may need to be stronger

================================================================================
OUTPUT FILES
================================================================================
Log directory:         logs/improved_20251102_223040
Board states:          board_states.txt
Episode log (CSV):     episode_log.csv
Reward plot:           reward_progress.png
Metrics plot:          training_metrics.png
Debug summary:         DEBUG_SUMMARY.txt (this file)

================================================================================
USEFUL DEBUG COMMANDS
================================================================================
View recent board states:
  tail -100 logs/improved_20251102_223040/board_states.txt

Analyze hole progression:
  awk -F',' 'NR>1 {print $4,$6}' logs/improved_20251102_223040/episode_log.csv | tail -100

Check line clearing progress:
  awk -F',' 'NR>1 {sum+=$7} NR%1000==0 {print NR,sum}' logs/improved_20251102_223040/episode_log.csv

Resume training:
  python train_progressive_improved.py --episodes 19112 --resume

================================================================================
END OF DEBUG SUMMARY
================================================================================